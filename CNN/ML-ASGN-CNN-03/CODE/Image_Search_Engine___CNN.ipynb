{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "name": "Image Search Engine _ CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dB69OBzHyn-8",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "57e5bde9-b381-427d-d8e5-107df9a918b5"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-349276dd-be69-4af1-a1ac-ec6769786532\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-349276dd-be69-4af1-a1ac-ec6769786532\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving dataset.zip to dataset.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nopO2B0j3-JT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "d53428a9-94f9-48da-c7e4-feb9c6977025"
      },
      "source": [
        "!unzip dataset.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  dataset.zip\n",
            "   creating: test/\n",
            "  inflating: test/0_cat.png          \n",
            "  inflating: test/1_ship.png         \n",
            "  inflating: test/2_ship.png         \n",
            "   creating: train/\n",
            "  inflating: train/0_frog.png        \n",
            "  inflating: train/1_truck.png       \n",
            "  inflating: train/2_truck.png       \n",
            "  inflating: labels.txt              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvjrFo0_0IXN",
        "colab_type": "text"
      },
      "source": [
        "#IMPORTING LIBRARIES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPgPHSveyeNr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "\n",
        "from tqdm import tqdm\n",
        "from scipy.spatial.distance import hamming, cosine, euclidean\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rU527ns2Xn7Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def image_loader(image_path, image_size):\n",
        "    '''\n",
        "    Load an image from a disk.\n",
        "    \n",
        "    :param image_path: String, path to the image\n",
        "    :param image_size: tuple, size of an output image Example: image_size=(32, 32)\n",
        "    '''\n",
        "    \n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = cv2.resize(image, image_size, cv2.INTER_CUBIC)\n",
        "    return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaKNObWTely2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dataset_preprocessing(dataset_path, labels_file_path, image_size, image_paths_pickle):\n",
        "    '''\n",
        "    Loads images and labels from dataset folder.\n",
        "    \n",
        "    :param dataset_path: String, path to the train/test dataset folder\n",
        "    :param labels_file_path: String, path to the .txt file where classes names are written\n",
        "    :param image_size: tuple, single image size\n",
        "    :param image_paths_pickle: String, name of a pickle file where all image paths will be saved\n",
        "    '''\n",
        "    \n",
        "    with open(labels_file_path, 'r') as f:\n",
        "        classes = f.read().split('\\n')[:-1]\n",
        "        \n",
        "    \n",
        "    images = []\n",
        "    labels = []\n",
        "    image_paths = []\n",
        "    \n",
        "    for image_name in os.listdir(dataset_path):\n",
        "        try:\n",
        "            image_path = os.path.join(dataset_path, image_name)\n",
        "            images.append(image_loader(image_path, image_size))\n",
        "            image_paths.append(image_path)\n",
        "            for idx in range(len(classes)):\n",
        "                if classes[idx] in image_name: #Example: 0_frog.png\n",
        "                    labels.append(idx)\n",
        "        except:\n",
        "            pass\n",
        "    \n",
        "    with open(image_paths_pickle + \".pickle\", 'wb') as f:\n",
        "        pickle.dump(image_paths, f)\n",
        "    \n",
        "    assert len(images) == len(labels)\n",
        "    return np.array(images), np.array(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYIEcnhYerYJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cosine_distance(training_set_vectors, query_vector, top_n=50):\n",
        "    '''\n",
        "    Calculates cosine distances between query image (vector) and all training set images (vectors).\n",
        "    \n",
        "    :param training_set_vectors: numpy Matrix, vectors for all images in the training set\n",
        "    :param query_vector: numpy vector, query image (new image) vector\n",
        "    :param top_n: integer, number of closest images to return\n",
        "    '''\n",
        "    \n",
        "    distances = []\n",
        "    \n",
        "    for i in range(len(training_set_vectors)): #For Cifar 10 -> 50k images\n",
        "        distances.append(cosine(training_set_vectors[i], query_vector[0]))\n",
        "        \n",
        "    return np.argsort(distances)[:top_n]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZ2gKQzvew4P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def hamming_distance(training_set_vectors, query_vector, top_n=50):\n",
        "    '''\n",
        "    Calculates hamming distances between query image (vector) and all training set images (vectors).\n",
        "    \n",
        "    :param training_set_vectors: numpy Matrix, vectors for all images in the training set\n",
        "    :param query_vector: numpy vector, query image (new image) vector\n",
        "    :param top_n: Integer, number of closest images to return\n",
        "    '''\n",
        "     \n",
        "    distances = []\n",
        "    \n",
        "    for i in range(len(training_set_vectors)): #For Cifar 10 -> 50k images\n",
        "        distances.append(hamming(training_set_vectors[i], query_vector[0]))\n",
        "        \n",
        "    return np.argsort(distances)[:top_n]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sld525vFfARN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sparse_accuracy(true_labels, predicted_labels):\n",
        "    '''\n",
        "    Calculates accuracy of a model based on softmax outputs.\n",
        "    \n",
        "    :param true_labels: numpy array, real labels of each sample. Example: [1, 2, 1, 0, 0]\n",
        "    :param predicted_labels: numpy matrix, softmax probabilities. Example [[0.2, 0.1, 0.7], [0.9, 0.05, 0.05]]\n",
        "    '''\n",
        "    \n",
        "    assert len(true_labels) == len(predicted_labels)\n",
        "    \n",
        "    correct = 0\n",
        "    \n",
        "    for i in range(len(true_labels)):\n",
        "        \n",
        "        if np.argmax(predicted_labels[i]) == true_labels[i]:\n",
        "            correct += 1\n",
        "            \n",
        "    return correct / len(true_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RitxSdZSfEcW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_inputs(image_size):\n",
        "    '''\n",
        "    Defines CNN inputs (placeholders).\n",
        "    \n",
        "    :param image_size: tuple, (height, width) of an image\n",
        "    '''\n",
        "    #-> [Batch_size, image_size[0], image_size[1], 3]\n",
        "    inputs = tf.placeholder(dtype=tf.float32, shape=[None, image_size[0], image_size[1], 3], name='images')\n",
        "    targets = tf.placeholder(dtype=tf.int32, shape=[None,], name='targets')\n",
        "    dropout_prob = tf.placeholder(dtype=tf.float32, name='dropout_probs')\n",
        "    \n",
        "    return inputs, targets, dropout_prob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocu0J1bpyeNx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_block(inputs, \n",
        "               number_of_filters, \n",
        "               kernel_size, \n",
        "               strides=(1, 1), \n",
        "               padding='SAME', \n",
        "               activation=tf.nn.relu, \n",
        "               max_pool=True, \n",
        "               batch_norm=True):\n",
        "    \n",
        "    '''\n",
        "    Defines convolutional block layer.\n",
        "    \n",
        "    :param inputs: data from a previous layer\n",
        "    :param number_of_filters: integer, number of conv filters\n",
        "    :param kernel_size: tuple, size of conv layer kernel\n",
        "    :param padding: string, type of padding technique: SAME or VALID\n",
        "    :param activation: tf.object, activation function used on the layer\n",
        "    :param max_pool: boolean, if true the conv block will use max_pool\n",
        "    :param batch_norm: boolean, if true the conv block will use batch normalization\n",
        "    '''\n",
        "    \n",
        "    conv_features = layer = tf.layers.conv2d(inputs=inputs, \n",
        "                                             filters=number_of_filters, \n",
        "                                             kernel_size=kernel_size, \n",
        "                                             strides=strides, \n",
        "                                             padding=padding, \n",
        "                                             activation=activation)\n",
        "    \n",
        "    if max_pool:\n",
        "        layer = tf.layers.max_pooling2d(layer, \n",
        "                                        pool_size=(2, 2), \n",
        "                                        strides=(2, 2),\n",
        "                                        padding='SAME')\n",
        "        \n",
        "    if batch_norm:\n",
        "        layer = tf.layers.batch_normalization(layer)\n",
        "        \n",
        "    return layer, conv_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKIKZ5LhOusF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dense_block(inputs, \n",
        "                units, \n",
        "                activation=tf.nn.relu, \n",
        "                dropout_rate=None, \n",
        "                batch_norm=True):\n",
        "    \n",
        "    '''\n",
        "    Defines dense block layer.\n",
        "    \n",
        "    :param inputs: data from a previous layer\n",
        "    :param units: integer, number of neurons/units for a dense layer\n",
        "    :param activation: tf.object, activation function used on the layer\n",
        "    :param dropout_rate: dropout rate used in this dense block\n",
        "    :param batch_norm: boolean, if true the conv block will use batch normalization\n",
        "    '''\n",
        "    \n",
        "    dense_features = layer = tf.layers.dense(inputs, \n",
        "                                             units=units, \n",
        "                                             activation=activation)\n",
        "    \n",
        "    if dropout_rate is not None:\n",
        "        layer = tf.layers.dropout(layer, rate=dropout_rate)\n",
        "    \n",
        "    if batch_norm:\n",
        "        layer = tf.layers.batch_normalization(layer)\n",
        "        \n",
        "    return layer, dense_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMKuaUa5O0dF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def opt_loss(logits, \n",
        "             targets, \n",
        "             learning_rate):\n",
        "    \n",
        "    '''\n",
        "    Defines model's optimizer and loss functions.\n",
        "    \n",
        "    :param logits: pre-activated model outputs\n",
        "    :param targets: true labels for each input sample\n",
        "    :param learning_rate: learning_rate\n",
        "    '''\n",
        "    \n",
        "    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=targets, logits=logits))\n",
        "    \n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
        "    \n",
        "    return loss, optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yte-F-1KqAXK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.framework import ops"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0FOAcGlhz7-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ImageSearchModel(object):\n",
        "    \n",
        "    def __init__(self, \n",
        "                 learning_rate, \n",
        "                 image_size, \n",
        "                 number_of_classes=10):\n",
        "        \n",
        "        '''\n",
        "        Defines CNN model.\n",
        "        \n",
        "        :param learning_rate: learning_rate\n",
        "        :param image_size: tuple, (height, width) of an image\n",
        "        :param number_of_classes: integer, number of classes in a dataset.\n",
        "        '''\n",
        "        \n",
        "        ops.reset_default_graph()\n",
        "        \n",
        "        #model inputs\n",
        "        self.inputs, self.targets, self.dropout_rate = model_inputs(image_size)\n",
        "        \n",
        "        normalized_images = tf.layers.batch_normalization(self.inputs)\n",
        "        \n",
        "        #conv_1 block\n",
        "        conv_block_1, self.conv_1_features = conv_block(inputs=normalized_images, \n",
        "                                                        number_of_filters=64, \n",
        "                                                        kernel_size=(3, 3), \n",
        "                                                        strides=(1, 1), \n",
        "                                                        padding='SAME', \n",
        "                                                        activation=tf.nn.relu, \n",
        "                                                        max_pool=True, \n",
        "                                                        batch_norm=True)\n",
        "        \n",
        " \n",
        "        #conv_2 block\n",
        "        conv_block_2, self.conv_2_features = conv_block(inputs=conv_block_1, \n",
        "                                                        number_of_filters=128, \n",
        "                                                        kernel_size=(3, 3), \n",
        "                                                        strides=(1, 1), \n",
        "                                                        padding='SAME', \n",
        "                                                        activation=tf.nn.relu, \n",
        "                                                        max_pool=True, \n",
        "                                                        batch_norm=True)\n",
        "        \n",
        "        #conv_3 block\n",
        "        conv_block_3, self.conv_3_features = conv_block(inputs=conv_block_2, \n",
        "                                                        number_of_filters=256, \n",
        "                                                        kernel_size=(5, 5), \n",
        "                                                        strides=(1, 1), \n",
        "                                                        padding='SAME', \n",
        "                                                        activation=tf.nn.relu, \n",
        "                                                        max_pool=True, \n",
        "                                                        batch_norm=True)\n",
        "        \n",
        "        #conv_4 block\n",
        "        conv_block_4, self.conv_4_features = conv_block(inputs=conv_block_3, \n",
        "                                                        number_of_filters=512, \n",
        "                                                        kernel_size=(5, 5), \n",
        "                                                        strides=(1, 1), \n",
        "                                                        padding='SAME', \n",
        "                                                        activation=tf.nn.relu, \n",
        "                                                        max_pool=True, \n",
        "                                                        batch_norm=True)\n",
        "        \n",
        "        #flattening\n",
        "        flat_layer = tf.layers.flatten(conv_block_4)\n",
        "        \n",
        "        #1st dense block\n",
        "        dense_block_1, dense_1_features = dense_block(inputs=flat_layer, \n",
        "                                                       units=128, \n",
        "                                                       activation=tf.nn.relu, \n",
        "                                                       dropout_rate=self.dropout_rate, \n",
        "                                                       batch_norm=True)\n",
        "        \n",
        "        #2nd dense block\n",
        "        dense_block_2, self.dense_2_features = dense_block(inputs=dense_block_1, \n",
        "                                                       units=256, \n",
        "                                                       activation=tf.nn.relu, \n",
        "                                                       dropout_rate=self.dropout_rate, \n",
        "                                                       batch_norm=True)\n",
        "        \n",
        "        #3rd dense block\n",
        "        dense_block_3, self.dense_3_features = dense_block(inputs=dense_block_2, \n",
        "                                                       units=512, \n",
        "                                                       activation=tf.nn.relu, \n",
        "                                                       dropout_rate=self.dropout_rate, \n",
        "                                                       batch_norm=True)\n",
        "        \n",
        "        #4th dense block\n",
        "        dense_block_4, self.dense_4_features = dense_block(inputs=dense_block_3, \n",
        "                                                       units=1024, \n",
        "                                                       activation=tf.nn.relu, \n",
        "                                                       dropout_rate=self.dropout_rate, \n",
        "                                                       batch_norm=True)\n",
        "        \n",
        "        #output layer\n",
        "        logits = tf.layers.dense(inputs=dense_block_4, \n",
        "                                 units=number_of_classes, \n",
        "                                 activation=None)\n",
        "        \n",
        "        self.predictions = tf.nn.softmax(logits)\n",
        "        \n",
        "        self.loss, self.optimizer = opt_loss(logits=logits, \n",
        "                                             targets=self.targets, \n",
        "                                             learning_rate=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qH6XZSwtiCGA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, \n",
        "          epochs,\n",
        "          drop_rate,\n",
        "          batch_size, \n",
        "          data, \n",
        "          save_dir, \n",
        "          saver_delta=0.15):\n",
        "    \n",
        "    '''\n",
        "    The core training function, use this function to train a model.\n",
        "    \n",
        "    :param model: CNN model\n",
        "    :param epochs: integer, number of epochs\n",
        "    :param drop_rate: float, dropout_rate\n",
        "    :param batch_size: integer, number of samples to put through the model at once\n",
        "    :param data: tuple, train-test data Example(X_train, y_train, X_test, y_test)\n",
        "    :param save_dir: string, path to a folder where model checkpoints will be saved\n",
        "    :param saver_delta: float, used to prevent overfitted model to be saved\n",
        "    '''\n",
        "    \n",
        "    X_train, y_train, X_test, y_test = data\n",
        "    \n",
        "    #start session\n",
        "    session = tf.Session()\n",
        "    session.run(tf.global_variables_initializer())\n",
        "    \n",
        "    #define saver\n",
        "    saver = tf.train.Saver()\n",
        "    \n",
        "    best_test_accuracy = 0.0\n",
        "    #start training loop\n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        train_accuracy = []\n",
        "        train_loss = []\n",
        "        \n",
        "        for ii in tqdm(range(len(X_train) // batch_size)):\n",
        "            start_id = ii*batch_size\n",
        "            end_id = start_id + batch_size\n",
        "            \n",
        "            X_batch = X_train[start_id:end_id]\n",
        "            y_batch = y_train[start_id:end_id]\n",
        "            \n",
        "            feed_dict = {model.inputs:X_batch, \n",
        "                         model.targets:y_batch, \n",
        "                         model.dropout_rate:drop_rate}\n",
        "            \n",
        "            _, t_loss, preds_t = session.run([model.optimizer, model.loss, model.predictions], feed_dict=feed_dict)\n",
        "            \n",
        "            train_accuracy.append(sparse_accuracy(y_batch, preds_t))\n",
        "            train_loss.append(t_loss)\n",
        "            \n",
        "        print(\"Epoch: {}/{}\".format(epoch, epochs),  \n",
        "              \" | Training accuracy: {}\".format(np.mean(train_accuracy)), \n",
        "              \" | Training loss: {}\".format(np.mean(train_loss)) )\n",
        "        \n",
        "        test_accuracy = []\n",
        "        \n",
        "        for ii in tqdm(range(len(X_test) // batch_size)):\n",
        "            start_id = ii*batch_size\n",
        "            end_id = start_id + batch_size\n",
        "            \n",
        "            X_batch = X_test[start_id:end_id]\n",
        "            y_batch = y_test[start_id:end_id]\n",
        "            \n",
        "            feed_dict = {model.inputs:X_batch, \n",
        "                         model.dropout_rate:0.0}\n",
        "            \n",
        "            preds_test = session.run(model.predictions, feed_dict=feed_dict)\n",
        "            test_accuracy.append(sparse_accuracy(y_batch, preds_test))\n",
        "            \n",
        "        print(\"Test accuracy: {}\".format(np.mean(test_accuracy)))\n",
        "        \n",
        "        #saving the model\n",
        "        if np.mean(train_accuracy) > np.mean(test_accuracy): #to prevent underfitting\n",
        "            if np.abs(np.mean(train_accuracy) - np.mean(test_accuracy)) <= saver_delta: #to prevent overfit\n",
        "                if np.mean(test_accuracy) >= best_test_accuracy:\n",
        "                    best_test_accuracy = np.mean(test_accuracy)\n",
        "                    saver.save(session, \"{}/model_epoch_{}.ckpt\".format(save_dir, epoch))\n",
        "                    \n",
        "    session.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQ3uY_4DiFoY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 20\n",
        "batch_size = 128\n",
        "learning_rate = 0.001\n",
        "dropout_probs = 0.6\n",
        "image_size = (32, 32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4-hp2b8nYJD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, y_train = dataset_preprocessing('train/', 'labels.txt', image_size=image_size, image_paths_pickle=\"train_images_pickle\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uK79fNEUnmDw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "152cc3fa-336e-4797-8536-2413a89ae382"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zA9iJQ5BpN-r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "X_test, y_test = dataset_preprocessing('test/', 'labels.txt', image_size=image_size, image_paths_pickle=\"test_images_pickle\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMPmxT7NpciP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c0a2bf38-4bf2-4e4d-d2f5-08aa1e2b86f9"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQ6PMraLrZMz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "tf.disable_v2_behavior()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymY9bBXEpfP3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define the model\n",
        "model = ImageSearchModel(learning_rate, image_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cA-baMZVpnIW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = (X_train, y_train, X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfAtY37Fqg-j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1cc8e2d0-01cb-41b6-97f8-b5cd4ff5ec04"
      },
      "source": [
        "train(model, epochs, dropout_probs, batch_size, data, 'saver')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0/20  | Training accuracy: nan  | Training loss: nan\n",
            "Test accuracy: nan\n",
            "Epoch: 1/20  | Training accuracy: nan  | Training loss: nan\n",
            "Test accuracy: nan\n",
            "Epoch: 2/20  | Training accuracy: nan  | Training loss: nan\n",
            "Test accuracy: nan\n",
            "Epoch: 3/20  | Training accuracy: nan  | Training loss: nan\n",
            "Test accuracy: nan\n",
            "Epoch: 4/20  | Training accuracy: nan  | Training loss: nan\n",
            "Test accuracy: nan\n",
            "Epoch: 5/20  | Training accuracy: nan  | Training loss: nan\n",
            "Test accuracy: nan\n",
            "Epoch: 6/20  | Training accuracy: nan  | Training loss: nan\n",
            "Test accuracy: nan\n",
            "Epoch: 7/20  | Training accuracy: nan  | Training loss: nan\n",
            "Test accuracy: nan\n",
            "Epoch: 8/20  | Training accuracy: nan  | Training loss: nan\n",
            "Test accuracy: nan\n",
            "Epoch: 9/20  | Training accuracy: nan  | Training loss: nan\n",
            "Test accuracy: nan\n",
            "Epoch: 10/20  | Training accuracy: nan  | Training loss: nan\n",
            "Test accuracy: nan\n",
            "Epoch: 11/20  | Training accuracy: nan  | Training loss: nan\n",
            "Test accuracy: nan\n",
            "Epoch: 12/20  | Training accuracy: nan  | Training loss: nan\n",
            "Test accuracy: nan\n",
            "Epoch: 13/20  | Training accuracy: nan  | Training loss: nan\n",
            "Test accuracy: nan\n",
            "Epoch: 14/20  | Training accuracy: nan  | Training loss: nan\n",
            "Test accuracy: nan\n",
            "Epoch: 15/20  | Training accuracy: nan  | Training loss: nan\n",
            "Test accuracy: nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 16/20  | Training accuracy: nan  | Training loss: nan\n",
            "Test accuracy: nan\n",
            "Epoch: 17/20  | Training accuracy: nan  | Training loss: nan\n",
            "Test accuracy: nan\n",
            "Epoch: 18/20  | Training accuracy: nan  | Training loss: nan\n",
            "Test accuracy: nan\n",
            "Epoch: 19/20  | Training accuracy: nan  | Training loss: nan\n",
            "Test accuracy: nan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_8bGOFusF3e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "61fbb38e-4541-423b-f30b-4d64e043329e"
      },
      "source": [
        "w = 10\n",
        "h = 10\n",
        "fig = plt.figure(figsize=(16, 16))\n",
        "colums = 10\n",
        "rows = 5\n",
        "for i in range(1, colums*rows+1):\n",
        "    try:\n",
        "        image = image_loader(train_image_paths[result_ids[i]], image_size)\n",
        "        fig.add_subplot(rows, colums, i)\n",
        "        plt.imshow(image)\n",
        "    except:\n",
        "        pass\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x1152 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}